---
layout: post
title: Llama Local Deployment
index_img: /img/ai/llama.jpeg
date: 2024-07-23 16:10:26
sticky: 110
tags:
    - AI
    - GPU
    - LLM
    - LLAMA
categories: 
    - AI
---

Chinese-LLaMA-Alpaca æ˜¯åŸºäº Meta å‘å¸ƒçš„å¯å•†ç”¨å¤§æ¨¡å‹ Llama å¼€å‘ï¼Œllama.cpp æ˜¯ä¸€ä¸ª C++ è¯­è¨€éƒ¨ç½² Llama çš„æ¡†æ¶ã€‚

<!-- more -->

- [llama.cpp](https://github.com/ggerganov/llama.cpp)

# llama 2

- [Chinese-LLaMA-Alpaca-2](https://github.com/ymcui/Chinese-LLaMA-Alpaca-2)

## éƒ¨ç½²

- [é•¿ä¸Šä¸‹æ–‡ç‰ˆæ¨¡å‹ Chinese-Alpaca-2-7B-64K](https://huggingface.co/hfl/chinese-alpaca-2-7b-64k-gguf/tree/main)
- [llama.cppéƒ¨ç½²æ•™ç¨‹](https://github.com/ymcui/Chinese-LLaMA-Alpaca-2/wiki/llamacpp_zh)

æ³¨ï¼šFP16ç‰ˆæœ¬è¾ƒæ…¢ï¼Œå¯ä»¥ä¸‹`q8_0`æˆ–`Q6_K`ï¼Œéå¸¸æ¥è¿‘F16æ¨¡å‹çš„æ•ˆæœã€‚

```bash
git clone https://github.com/ggerganov/llama.cpp
cd llama.cpp

make GGML_CUDA=1
./chat.sh model/chinese-alpaca-2-7b-64k-ggml-model-f16.gguf 'ä»‹ç»ä¸€ä¸‹åŒ—äº¬'
```

- `chat.sh` å†…å®¹ï¼š

```bash
#!/bin/bash

# temporary script to chat with Chinese Alpaca-2 model
# usage: ./chat.sh alpaca2-ggml-model-path your-first-instruction

SYSTEM='You are a helpful assistant. ä½ æ˜¯ä¸€ä¸ªä¹äºåŠ©äººçš„åŠ©æ‰‹ã€‚'
FIRST_INSTRUCTION=$2

# æ³¨ï¼Œæ–°ç‰ˆ llama.cpp æ‹†åˆ†äº†ç¼–è¯‘çš„ main å¯æ‰§è¡Œæ–‡ä»¶
./llama-cli -m $1 \
--color -i -c 4096 -t 8 --temp 0.5 --top_k 40 --top_p 0.9 --repeat_penalty 1.1 \
--in-prefix-bos -ngl 40 --in-prefix ' [INST] ' --in-suffix ' [/INST]' -p \
"[INST] <<SYS>>
$SYSTEM
<</SYS>>

$FIRST_INSTRUCTION [/INST]"
```

{% note primary %}
GPUç‰ˆæœ¬éœ€è¦ç”¨`-ngl 40`å‚æ•°æŒ‡å®šï¼ˆå¿…é¡»ç¼–è¯‘CUDAç‰ˆæœ¬ï¼‰ã€‚
{% endnote %}

![LLAMA](/img/ai/llama_gpu.png)

## server è®¾ç½®

```bash
./llama-server -m model/chinese-alpaca-2-7b-64k-ggml-model-q8_0.gguf -c 4096 -ngl 40
```

åˆ›å»ºä¸€ä¸ªclientè„šæœ¬ï¼š

```bash
# server_curl_example.sh

SYSTEM_PROMPT='You are a helpful assistant. ä½ æ˜¯ä¸€ä¸ªä¹äºåŠ©äººçš„åŠ©æ‰‹ã€‚'
# SYSTEM_PROMPT='You are a helpful assistant. ä½ æ˜¯ä¸€ä¸ªä¹äºåŠ©äººçš„åŠ©æ‰‹ã€‚è¯·ä½ æä¾›ä¸“ä¸šã€æœ‰é€»è¾‘ã€å†… å®¹çœŸå®ã€æœ‰ä»·å€¼çš„è¯¦ç»†å›å¤ã€‚' # Try this one, if you prefer longer response.
INSTRUCTION=$1
ALL_PROMPT="[INST] <<SYS>>\n$SYSTEM_PROMPT\n<</SYS>>\n\n$INSTRUCTION [/INST]"
CURL_DATA="{\"prompt\": \"$ALL_PROMPT\",\"n_predict\": 128}"

curl --request POST \
    --url http://localhost:8080/completion \
    --header "Content-Type: application/json" \
    --data "$CURL_DATA"

echo
```

```bash
./server_curl_example.sh 'è¯·åˆ—ä¸¾5æ¡æ–‡æ˜ä¹˜è½¦çš„å»ºè®®'
```

![LLAMA Server](/img/ai/llama_server.png)

{% fold @è¿è¡Œåè¿”å›ä¸€ä¸ªjsonæ¡ç›® %}

```json
{
    "content": " 1. ä¿æŒç§©åºï¼šå°½é‡ä¿æŒè½¦å†…å®‰é™ï¼Œå°Šé‡ä»–äººçš„æƒç›Šã€‚ä¸è¦å¤§å£°å–§å“—ã€å¤§å£°æ‰“ç”µè¯æˆ–ä½¿ç”¨ç”µå­è®¾å¤‡ï¼Œä»¥ å…å¹²æ‰°ä»–äººçš„ä¼‘æ¯å’Œå­¦ä¹ ã€‚\n\n2. ä¸å¸çƒŸï¼šåœ¨ä¹˜è½¦è¿‡ç¨‹ä¸­ï¼Œä¸å¸çƒŸæˆ–ä½¿ç”¨ç”µå­çƒŸï¼Œä»¥ä¿æŒè½¦å†…ç©ºæ°”è´¨é‡ï¼Œå¹¶å°Šé‡ä»–äººçš„å¥åº·ã€‚\n\n3. æ³¨æ„ä¸ªäººå«ç”Ÿï¼šå°½é‡é¿å…åœ¨è½¦å†…è¿›é£Ÿã€åš¼å£é¦™ç³–ã€åç—°ç­‰ï¼Œä¿æŒè½¦å†…çš„å«ç”Ÿå’Œæ¸…æ´ã€‚åŒæ—¶ï¼Œä¿æŒä¸ªäººå«ç”Ÿï¼Œå¦‚æ´—æ‰‹ã€æ´—è„¸ç­‰ï¼Œä»¥å‡å°‘ç»†èŒå’Œç—…æ¯’ä¼ æ’­çš„é£é™©ã€‚\n\n4. éµå®ˆä¹˜è½¦è§„åˆ™ï¼šéµå®ˆä¹˜è½¦",
    "id_slot": 0,
    "stop": true,
    "model": "model/chinese-alpaca-2-7b-64k-ggml-model-q8_0.gguf",
    "tokens_predicted": 128,
    "tokens_evaluated": 43,
    "generation_settings": {
        "n_ctx": 4096,
        "n_predict": -1,
        "model": "model/chinese-alpaca-2-7b-64k-ggml-model-q8_0.gguf",
        "seed": 4294967295,
        "temperature": 0.800000011920929,
        "dynatemp_range": 0.0,
        "dynatemp_exponent": 1.0,
        "top_k": 40,
        "top_p": 0.949999988079071,
        "min_p": 0.05000000074505806,
        "tfs_z": 1.0,
        "typical_p": 1.0,
        "repeat_last_n": 64,
        "repeat_penalty": 1.0,
        "presence_penalty": 0.0,
        "frequency_penalty": 0.0,
        "penalty_prompt_tokens": [],
        "use_penalty_prompt_tokens": false,
        "mirostat": 0,
        "mirostat_tau": 5.0,
        "mirostat_eta": 0.10000000149011612,
        "penalize_nl": false,
        "stop": [],
        "n_keep": 0,
        "n_discard": 0,
        "ignore_eos": false,
        "stream": false,
        "logit_bias": [],
        "n_probs": 0,
        "min_keep": 0,
        "grammar": "",
        "samplers": [
            "top_k",
            "tfs_z",
            "typical_p",
            "top_p",
            "min_p",
            "temperature"
        ]
    },
    "prompt": "[INST] <<SYS>>\nYou are a helpful assistant. ä½ æ˜¯ä¸€ä¸ªä¹äºåŠ©äººçš„åŠ©æ‰‹ã€‚\n<</SYS>>\n\nè¯·åˆ—ä¸¾5æ¡æ–‡æ˜ä¹˜è½¦çš„å»ºè®® [/INST]",
    "truncated": false,
    "stopped_eos": false,
    "stopped_word": false,
    "stopped_limit": true,
    "stopping_word": "",
    "tokens_cached": 170,
    "timings": {
        "prompt_n": 43,
        "prompt_ms": 244.353,
        "prompt_per_token_ms": 5.6826279069767445,
        "prompt_per_second": 175.97492152746233,
        "predicted_n": 128,
        "predicted_ms": 2295.145,
        "predicted_per_token_ms": 17.9308203125,
        "predicted_per_second": 55.7698968910461
    }
}
```

{% endfold %}

## Jetson Orin Nano

- [Your GPU Compute Capability](https://developer.nvidia.com/cuda-gpus)
- [chinese-alpaca-2-1.3b-gguf](https://huggingface.co/hfl/chinese-alpaca-2-1.3b-gguf) ä¸‹è½½ `q_2k` ç‰ˆæœ¬ï¼Œå…¶ä»–æœªæµ‹è¯•

å› ä¸ºcudaç‰ˆæœ¬ä½ï¼Œç¼–è¯‘llama.cppå‰éœ€è¦æŒ‡å®šè®¡ç®—èƒ½åŠ›:

```bash
export CUDA_DOCKER_ARCH=compute_87
make GGML_CUDA=1 -j 4
```

å…¶ä»–é…ç½®åŒä¸Š

![Jetson è¿è¡Œ Llama](/img/ai/llama_jetson.png)

{% note primary %}
ç¬¬ä¸€æ¬¡æ‰§è¡Œå¯¼å…¥æ¨¡å‹ä¼šå¾ˆæ…¢ï¼Œä¹‹åä¼šå˜å¿«å¾ˆå¤šã€‚å›¾å³è¾¹ä¸º`jtop`æŒ‡ä»¤æ˜¾ç¤ºGPUå ç”¨æƒ…å†µã€‚
{% endnote %}

æµ‹è¯•é•¿ä¸Šä¸‹æ–‡ `7B q_2k`: [chinese-alpaca-2-7b-64k-gguf](https://huggingface.co/hfl/chinese-alpaca-2-7b-64k-gguf/tree/main), æ˜¾è‘—æé«˜äº†æ˜¾å­˜å ç”¨ç‡ã€‚

![Jetson è¿è¡Œ Llama 7B](/img/ai/llama_jetson2.png)

## ollama éƒ¨ç½²

- [ollamaéƒ¨ç½²ä½“éªŒChinese-LLaMA-Alpaca-3å¤§æ¨¡å‹é¡¹ç›®](https://blog.csdn.net/nlpstarter/article/details/138910697)
- [ollamaä¸‹è½½åœ°å€](https://ollama.com/download)
- [ollamaä»“åº“](https://github.com/ollama/ollama?tab=readme-ov-file)

é¦–æ¬¡è¿è¡Œ`ollama run llama3`ï¼Œä¼šè”ç½‘åŠ è½½æ¨¡å‹ï¼š

```bash
$ ollama run llama3
pulling manifest
pulling 6a0746a1ec1a... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  4.7 GB
pulling 4fa551d4f938... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  12 KB
pulling 8ab4849b038c... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  254 B
pulling 577073ffcc6c... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  110 B
pulling 3f8eb4da87fa... 100% â–•â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  485 B
verifying sha256 digest
writing manifest
removing any unused layers
success
```

![Ollama](/img/ai/ollama.png)

å®æµ‹æ˜¯è‡ªåŠ¨è¿è¡Œäº†GPUåŠ é€Ÿçš„ã€‚

ä½“éªŒæœ¬åœ°ä¸­æ–‡LLama2å¤§æ¨¡å‹ï¼Œå‚è€ƒ[ä½¿ç”¨Ollamaè¿›è¡ŒèŠå¤©](https://github.com/ymcui/Chinese-LLaMA-Alpaca-3/wiki/ollama_zh)ï¼ŒModelfileå¦‚ä¸‹ï¼š

```bash
FROM D:\work\LLAMA-Chinese-Model\chinese-alpaca-2-7b-64k-ggml-model-q8_0.gguf
TEMPLATE """{{ if .System }}<|start_header_id|>system<|end_header_id|>

{{ .System }}<|eot_id|>{{ end }}{{ if .Prompt }}<|start_header_id|>user<|end_header_id|>

{{ .Prompt }}<|eot_id|>{{ end }}<|start_header_id|>assistant<|end_header_id|>

{{ .Response }}<|eot_id|>"""
SYSTEM """You are a helpful assistant. ä½ æ˜¯ä¸€ä¸ªä¹äºåŠ©äººçš„åŠ©æ‰‹ã€‚è¯·ä½ æä¾›ä¸“ä¸šã€æœ‰é€»è¾‘ã€å†… å®¹çœŸå®ã€æœ‰ä»·å€¼çš„è¯¦ç»†å›å¤ã€‚"""
PARAMETER temperature 0.2
PARAMETER num_keep 24
PARAMETER stop <|start_header_id|>
PARAMETER stop <|end_header_id|>
PARAMETER stop <|eot_id|>
```

![Ollama](/img/ai/ollama_zh.png)

## æ¨¡å‹ä¸‹è½½

### æ¨¡å‹é€‰æ‹©æŒ‡å¼•

ä»¥ä¸‹æ˜¯ä¸­æ–‡LLaMA-2å’ŒAlpaca-2æ¨¡å‹çš„å¯¹æ¯”ä»¥åŠå»ºè®®ä½¿ç”¨åœºæ™¯ã€‚**å¦‚éœ€èŠå¤©äº¤äº’ï¼Œè¯·é€‰æ‹©Alpacaè€Œä¸æ˜¯LLaMAã€‚[^1]**

| å¯¹æ¯”é¡¹                   |                                   ä¸­æ–‡LLaMA-2                                    |                                   ä¸­æ–‡Alpaca-2                                   |
| :----------------------- | :------------------------------------------------------------------------------: | :------------------------------------------------------------------------------: |
| æ¨¡å‹ç±»å‹                 |                                   **åŸºåº§æ¨¡å‹**                                   |                          **æŒ‡ä»¤/Chatæ¨¡å‹ï¼ˆç±»ChatGPTï¼‰**                          |
| å·²å¼€æºå¤§å°               |                                  1.3Bã€7Bã€13B                                   |                                  1.3Bã€7Bã€13B                                   |
| è®­ç»ƒç±»å‹                 |                                 Causal-LM (CLM)                                  |                                     æŒ‡ä»¤ç²¾è°ƒ                                     |
| è®­ç»ƒæ–¹å¼                 |                   7Bã€13Bï¼šLoRA + å…¨é‡emb/lm-head; 1.3Bï¼šå…¨é‡                    |                   7Bã€13Bï¼šLoRA + å…¨é‡emb/lm-head; 1.3Bï¼šå…¨é‡                    |
| åŸºäºä»€ä¹ˆæ¨¡å‹è®­ç»ƒ         |       [åŸç‰ˆLlama-2](https://github.com/facebookresearch/llama)ï¼ˆéchatç‰ˆï¼‰       |                                   ä¸­æ–‡LLaMA-2                                    |
| è®­ç»ƒè¯­æ–™                 |                           æ— æ ‡æ³¨é€šç”¨è¯­æ–™ï¼ˆ120Gçº¯æ–‡æœ¬ï¼‰                           |                            æœ‰æ ‡æ³¨æŒ‡ä»¤æ•°æ®ï¼ˆ500ä¸‡æ¡ï¼‰                             |
| è¯è¡¨å¤§å°[^2]   |                                      55,296                                      |                                      55,296                                      |
| ä¸Šä¸‹æ–‡é•¿åº¦[^3] | æ ‡å‡†ç‰ˆï¼š4Kï¼ˆ12K-18Kï¼‰; é•¿ä¸Šä¸‹æ–‡ç‰ˆï¼ˆPIï¼‰ï¼š16Kï¼ˆ24K-32Kï¼‰; é•¿ä¸Šä¸‹æ–‡ç‰ˆï¼ˆYaRNï¼‰ï¼š64K | æ ‡å‡†ç‰ˆï¼š4Kï¼ˆ12K-18Kï¼‰; é•¿ä¸Šä¸‹æ–‡ç‰ˆï¼ˆPIï¼‰ï¼š16Kï¼ˆ24K-32Kï¼‰; é•¿ä¸Šä¸‹æ–‡ç‰ˆï¼ˆYaRNï¼‰ï¼š64K |
| è¾“å…¥æ¨¡æ¿                 |                                      ä¸éœ€è¦                                      |                 éœ€è¦å¥—ç”¨ç‰¹å®šæ¨¡æ¿[^4]ï¼Œç±»ä¼¼Llama-2-Chat                 |
| é€‚ç”¨åœºæ™¯                 |                        æ–‡æœ¬ç»­å†™ï¼šç»™å®šä¸Šæ–‡ï¼Œè®©æ¨¡å‹ç”Ÿæˆä¸‹æ–‡                        |                        æŒ‡ä»¤ç†è§£ï¼šé—®ç­”ã€å†™ä½œã€èŠå¤©ã€äº¤äº’ç­‰                        |
| ä¸é€‚ç”¨åœºæ™¯               |                              æŒ‡ä»¤ç†è§£ ã€å¤šè½®èŠå¤©ç­‰                               |                                æ–‡æœ¬æ— é™åˆ¶è‡ªç”±ç”Ÿæˆ                                |
| åå¥½å¯¹é½                 |                                        æ—                                         |                               RLHFç‰ˆæœ¬ï¼ˆ1.3Bã€7Bï¼‰                               |

### å®Œæ•´æ¨¡å‹ä¸‹è½½

ä»¥ä¸‹æ˜¯å®Œæ•´ç‰ˆæ¨¡å‹ï¼Œç›´æ¥ä¸‹è½½å³å¯ä½¿ç”¨ï¼Œæ— éœ€å…¶ä»–åˆå¹¶æ­¥éª¤ã€‚æ¨èç½‘ç»œå¸¦å®½å……è¶³çš„ç”¨æˆ·ã€‚

| æ¨¡å‹åç§°              |   ç±»å‹   |  å¤§å°   |                                                                                                                                                           ä¸‹è½½åœ°å€                                                                                                                                                           |                              GGUF                              |
| :-------------------- | :------: | :-----: | :--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------: | :------------------------------------------------------------: |
| Chinese-LLaMA-2-13B   | åŸºåº§æ¨¡å‹ | 24.7 GB |   [[Baidu]](https://pan.baidu.com/s/1T3RqEUSmyg6ZuBwMhwSmoQ?pwd=e9qy) [[Google]](https://drive.google.com/drive/folders/1YNa5qJ0x59OEOI7tNODxea-1YvMPoH05?usp=share_link) ï¼›[[ğŸ¤—HF]](https://huggingface.co/hfl/chinese-llama-2-13b) ï¼›[[ğŸ¤–ModelScope]](https://modelscope.cn/models/ChineseAlpacaGroup/chinese-llama-2-13b)   |  [[ğŸ¤—HF]](https://huggingface.co/hfl/chinese-llama-2-13b-gguf)  |
| Chinese-LLaMA-2-7B    | åŸºåº§æ¨¡å‹ | 12.9 GB |    [[Baidu]](https://pan.baidu.com/s/1E5NI3nlQpx1j8z3eIzbIlg?pwd=n8k3) [[Google]](https://drive.google.com/drive/folders/18pp4I-mvQxRA7b8vF9gP-2cH_ocnXVKh?usp=share_link) ï¼›[[ğŸ¤—HF]](https://huggingface.co/hfl/chinese-llama-2-7b) ï¼›[[ğŸ¤–ModelScope]](https://modelscope.cn/models/ChineseAlpacaGroup/chinese-llama-2-7b)    |  [[ğŸ¤—HF]](https://huggingface.co/hfl/chinese-llama-2-7b-gguf)   |
| Chinese-LLaMA-2-1.3B  | åŸºåº§æ¨¡å‹ | 2.4 GB  |  [[Baidu]](https://pan.baidu.com/s/1hEuOCllnJJ5NMEZJf8OkRw?pwd=nwjg) [[Google]](https://drive.google.com/drive/folders/1Sd3PA_gs6JctXtBg5HwmHXh9GX93riMP?usp=share_link) ï¼›[[ğŸ¤—HF]](https://huggingface.co/hfl/chinese-llama-2-1.3b) ï¼›[[ğŸ¤–ModelScope]](https://modelscope.cn/models/ChineseAlpacaGroup/chinese-llama-2-1.3b)  | [[ğŸ¤—HF]](https://huggingface.co/hfl/chinese-llama-2-1.3b-gguf)  |
| Chinese-Alpaca-2-13B  | æŒ‡ä»¤æ¨¡å‹ | 24.7 GB |  [[Baidu]](https://pan.baidu.com/s/1MT_Zlap1OtdYMgoBNTS3dg?pwd=9xja) [[Google]](https://drive.google.com/drive/folders/1MTsKlzR61xmbTR4hBWzQas_MOpUZsogN?usp=share_link) ï¼›[[ğŸ¤—HF]](https://huggingface.co/hfl/chinese-alpaca-2-13b) ï¼›[[ğŸ¤–ModelScope]](https://modelscope.cn/models/ChineseAlpacaGroup/chinese-alpaca-2-13b)  | [[ğŸ¤—HF]](https://huggingface.co/hfl/chinese-alpaca-2-13b-gguf)  |
| Chinese-Alpaca-2-7B   | æŒ‡ä»¤æ¨¡å‹ | 12.9 GB |   [[Baidu]](https://pan.baidu.com/s/1wxx-CdgbMupXVRBcaN4Slw?pwd=kpn9) [[Google]](https://drive.google.com/drive/folders/1JsJDVs7tE2y31PBNleBlDPsB7S0ZrY8d?usp=share_link) ï¼›[[ğŸ¤—HF]](https://huggingface.co/hfl/chinese-alpaca-2-7b) ï¼›[[ğŸ¤–ModelScope]](https://modelscope.cn/models/ChineseAlpacaGroup/chinese-alpaca-2-7b)   |  [[ğŸ¤—HF]](https://huggingface.co/hfl/chinese-alpaca-2-7b-gguf)  |
| Chinese-Alpaca-2-1.3B | æŒ‡ä»¤æ¨¡å‹ | 2.4 GB  | [[Baidu]](https://pan.baidu.com/s/1PD7Ng-ltOIdUGHNorveptA?pwd=ar1p) [[Google]](https://drive.google.com/drive/folders/1h6qOy-Unvqs1_CJ8uPp0eKC61Gbbn8n7?usp=share_link) ï¼›[[ğŸ¤—HF]](https://huggingface.co/hfl/chinese-alpaca-2-1.3b) ï¼›[[ğŸ¤–ModelScope]](https://modelscope.cn/models/ChineseAlpacaGroup/chinese-alpaca-2-1.3b) | [[ğŸ¤—HF]](https://huggingface.co/hfl/chinese-alpaca-2-1.3b-gguf) |

### é•¿ä¸Šä¸‹æ–‡ç‰ˆæ¨¡å‹

ä»¥ä¸‹æ˜¯é•¿ä¸Šä¸‹æ–‡ç‰ˆæ¨¡å‹ï¼Œ**æ¨èä»¥é•¿æ–‡æœ¬ä¸ºä¸»çš„ä¸‹æ¸¸ä»»åŠ¡ä½¿ç”¨**ï¼Œå¦åˆ™å»ºè®®ä½¿ç”¨ä¸Šè¿°æ ‡å‡†ç‰ˆã€‚

| æ¨¡å‹åç§°                  |   ç±»å‹   |  å¤§å°   |                                                                                                                                                              ä¸‹è½½åœ°å€                                                                                                                                                               |                               GGUF                                |
| :------------------------ | :------: | :-----: | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------: | :---------------------------------------------------------------: |
| Chinese-LLaMA-2-7B-64K ğŸ†•  | åŸºåº§æ¨¡å‹ | 12.9 GB |   [[Baidu]](https://pan.baidu.com/s/1ShDQ2FG2QUJrvfnxCn4hwQ?pwd=xe5k) [[Google]][https://drive.google.com/drive/folders/17l9xJx55L2YNpqt7NiLVQzOZ6fV4rzJ-?usp=share_link]([ğŸ¤—HF)](https://huggingface.co/hfl/chinese-llama-2-7b-64k) [[ğŸ¤–ModelScope]](https://modelscope.cn/models/ChineseAlpacaGroup/chinese-llama-2-7b-64k)   |  [[ğŸ¤—HF]](https://huggingface.co/hfl/chinese-llama-2-7b-64k-gguf)  |
| Chinese-Alpaca-2-7B-64K ğŸ†• | æŒ‡ä»¤æ¨¡å‹ | 12.9 GB |  [[Baidu]](https://pan.baidu.com/s/1KBAr9PCGvX2oQkYfCuLEjw?pwd=sgp6) [[Google]][https://drive.google.com/drive/folders/13G_d5xcDnhtaMOaulj1BFiZbVoVwJ-Cu?usp=share_link]([ğŸ¤—HF)](https://huggingface.co/hfl/chinese-alpaca-2-7b-64k) [[ğŸ¤–ModelScope]](https://modelscope.cn/models/ChineseAlpacaGroup/chinese-alpaca-2-7b-64k)  | [[ğŸ¤—HF]](https://huggingface.co/hfl/chinese-alpaca-2-7b-64k-gguf)  |
| Chinese-LLaMA-2-13B-16K   | åŸºåº§æ¨¡å‹ | 24.7 GB |  [[Baidu]](https://pan.baidu.com/s/1XWrh3Ru9x4UI4-XmocVT2w?pwd=f7ik) [[Google]][https://drive.google.com/drive/folders/1nii6lF0DgB1u81CnsE4cCK2jD5oq_OW-?usp=share_link]([ğŸ¤—HF)](https://huggingface.co/hfl/chinese-llama-2-13b-16k) [[ğŸ¤–ModelScope]](https://modelscope.cn/models/ChineseAlpacaGroup/chinese-llama-2-13b-16k)  | [[ğŸ¤—HF]](https://huggingface.co/hfl/chinese-llama-2-13b-16k-gguf)  |
| Chinese-LLaMA-2-7B-16K    | åŸºåº§æ¨¡å‹ | 12.9 GB |   [[Baidu]](https://pan.baidu.com/s/1ZH7T7KU_up61ugarSIXw2g?pwd=pquq) [[Google]][https://drive.google.com/drive/folders/1Zc6jI5bl3myQbQsY79dWJJ8mP_fyf3iF?usp=share_link]([ğŸ¤—HF)](https://huggingface.co/hfl/chinese-llama-2-7b-16k) [[ğŸ¤–ModelScope]](https://modelscope.cn/models/ChineseAlpacaGroup/chinese-llama-2-7b-16k)   |  [[ğŸ¤—HF]](https://huggingface.co/hfl/chinese-llama-2-7b-16k-gguf)  |
| Chinese-Alpaca-2-13B-16K  | æŒ‡ä»¤æ¨¡å‹ | 24.7 GB | [[Baidu]](https://pan.baidu.com/s/1gIzRM1eg-Xx1xV-3nXW27A?pwd=qi7c) [[Google]][https://drive.google.com/drive/folders/1mOkYQCvEqtGoZ9DaIpYFweSkSia2Q0vl?usp=share_link]([ğŸ¤—HF)](https://huggingface.co/hfl/chinese-alpaca-2-13b-16k) [[ğŸ¤–ModelScope]](https://modelscope.cn/models/ChineseAlpacaGroup/chinese-alpaca-2-13b-16k) | [[ğŸ¤—HF]](https://huggingface.co/hfl/chinese-alpaca-2-13b-16k-gguf) |
| Chinese-Alpaca-2-7B-16K   | æŒ‡ä»¤æ¨¡å‹ | 12.9 GB |  [[Baidu]](https://pan.baidu.com/s/1Qk3U1LyvMb1RSr5AbiatPw?pwd=bfis) [[Google]][https://drive.google.com/drive/folders/1KBRSd2xAhiVQmamfA5wpm5ovYFRKuMdr?usp=share_link]([ğŸ¤—HF)](https://huggingface.co/hfl/chinese-alpaca-2-7b-16k) [[ğŸ¤–ModelScope]](https://modelscope.cn/models/ChineseAlpacaGroup/chinese-alpaca-2-7b-16k)  | [[ğŸ¤—HF]](https://huggingface.co/hfl/chinese-alpaca-2-7b-16k-gguf)  |

# llama 3

- [Chinese-LLaMA-Alpaca-3](https://github.com/ymcui/Chinese-LLaMA-Alpaca-3)
- [llama-3-chinese-8b-instruct-v3-gguf](https://huggingface.co/hfl/llama-3-chinese-8b-instruct-v3-gguf/tree/main)

## æ¨¡å‹ä¸‹è½½

| æ¨¡å‹åç§°                                          |                                                                                                                                       å®Œæ•´ç‰ˆ                                                                                                                                        |                                                                                                                                               LoRAç‰ˆ                                                                                                                                               |                                                                                           GGUFç‰ˆ                                                                                            |
| :------------------------------------------------ | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------: | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------: | :-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------: |
| **Llama-3-Chinese-8B-Instruct-v3**(æŒ‡ä»¤æ¨¡å‹) | [[ğŸ¤—HF]](https://huggingface.co/hfl/llama-3-chinese-8b-instruct-v3) [[ğŸ¤–ModelScope]][https://modelscope.cn/models/ChineseAlpacaGroup/llama-3-chinese-8b-instruct-v3]([ğŸŸ£wisemodel)](https://wisemodel.cn/models/ChineseAlpacaGroup/llama-3-chinese-8b-instruct-v3) |                                                                                                                                                N/A                                                                                                                                                 | [[ğŸ¤—HF]](https://huggingface.co/hfl/llama-3-chinese-8b-instruct-v3-gguf) [[ğŸ¤–ModelScope]](https://modelscope.cn/models/ChineseAlpacaGroup/llama-3-chinese-8b-instruct-v3-gguf) |
| **Llama-3-Chinese-8B-Instruct-v2**(æŒ‡ä»¤æ¨¡å‹) | [[ğŸ¤—HF]](https://huggingface.co/hfl/llama-3-chinese-8b-instruct-v2) [[ğŸ¤–ModelScope]][https://modelscope.cn/models/ChineseAlpacaGroup/llama-3-chinese-8b-instruct-v2]([ğŸŸ£wisemodel)](https://wisemodel.cn/models/ChineseAlpacaGroup/llama-3-chinese-8b-instruct-v2) | [[ğŸ¤—HF]](https://huggingface.co/hfl/llama-3-chinese-8b-instruct-v2-lora) [[ğŸ¤–ModelScope]][https://modelscope.cn/models/ChineseAlpacaGroup/llama-3-chinese-8b-instruct-v2-lora]([ğŸŸ£wisemodel)](https://wisemodel.cn/models/ChineseAlpacaGroup/llama-3-chinese-8b-instruct-v2-lora) | [[ğŸ¤—HF]](https://huggingface.co/hfl/llama-3-chinese-8b-instruct-v2-gguf) [[ğŸ¤–ModelScope]](https://modelscope.cn/models/ChineseAlpacaGroup/llama-3-chinese-8b-instruct-v2-gguf) |
| **Llama-3-Chinese-8B-Instruct**(æŒ‡ä»¤æ¨¡å‹)    |     [[ğŸ¤—HF]](https://huggingface.co/hfl/llama-3-chinese-8b-instruct) [[ğŸ¤–ModelScope]][https://modelscope.cn/models/ChineseAlpacaGroup/llama-3-chinese-8b-instruct]([ğŸŸ£wisemodel)](https://wisemodel.cn/models/ChineseAlpacaGroup/llama-3-chinese-8b-instruct)      |     [[ğŸ¤—HF]](https://huggingface.co/hfl/llama-3-chinese-8b-instruct-lora) [[ğŸ¤–ModelScope]][https://modelscope.cn/models/ChineseAlpacaGroup/llama-3-chinese-8b-instruct-lora]([ğŸŸ£wisemodel)](https://wisemodel.cn/models/ChineseAlpacaGroup/llama-3-chinese-8b-instruct-lora)      |    [[ğŸ¤—HF]](https://huggingface.co/hfl/llama-3-chinese-8b-instruct-gguf) [[ğŸ¤–ModelScope]](https://modelscope.cn/models/ChineseAlpacaGroup/llama-3-chinese-8b-instruct-gguf)    |
| **Llama-3-Chinese-8B**(åŸºåº§æ¨¡å‹)             |                   [[ğŸ¤—HF]](https://huggingface.co/hfl/llama-3-chinese-8b) [[ğŸ¤–ModelScope]][https://modelscope.cn/models/ChineseAlpacaGroup/llama-3-chinese-8b]([ğŸŸ£wisemodel)](https://wisemodel.cn/models/ChineseAlpacaGroup/llama-3-chinese-8b)                   |                   [[ğŸ¤—HF]](https://huggingface.co/hfl/llama-3-chinese-8b-lora) [[ğŸ¤–ModelScope]][https://modelscope.cn/models/ChineseAlpacaGroup/llama-3-chinese-8b-lora]([ğŸŸ£wisemodel)](https://wisemodel.cn/models/ChineseAlpacaGroup/llama-3-chinese-8b-lora)                   |             [[ğŸ¤—HF]](https://huggingface.co/hfl/llama-3-chinese-8b-gguf) [[ğŸ¤–ModelScope]](https://modelscope.cn/models/ChineseAlpacaGroup/llama-3-chinese-8b-gguf)             |

## éƒ¨ç½²

- [llama.cpp éƒ¨ç½²](https://github.com/ymcui/Chinese-LLaMA-Alpaca-3/wiki/llamacpp_zh)
- `chat_llama3.sh`:

```bash
FIRST_INSTRUCTION=$2
SYSTEM_PROMPT="You are a helpful assistant."

./llama-cli -m $1 --color -i \
-c 0 -t 6 --temp 0.2 --repeat_penalty 1.1 -ngl 40 \
-r '<|eot_id|>' \
--in-prefix '<|start_header_id|>user<|end_header_id|>\n\n' \
--in-suffix '<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n' \
-p "<|start_header_id|>system<|end_header_id|>\n\n$SYSTEM_PROMPT\n\n<|eot_id|><|start_header_id|>user<|end_header_id|>\n\n$FIRST_INSTRUCTION\n\n<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n\n"
```

- è¿è¡Œï¼š

```bash
./chat_llama3.sh model/llama-3-chinese-8b-instruct-v3-ggml-model-q8_0.gguf ä»‹ç»ä¸€ä¸‹åŒ—äº¬
```

## ollama éƒ¨ç½²

- `Modelfile_llama3`:

```bash
FROM D:\work\LLAMA-Chinese-Model\llama-3-chinese-8b-instruct-v3-ggml-model-q8_0.gguf
TEMPLATE """{{ if .System }}<|start_header_id|>system<|end_header_id|>

{{ .System }}<|eot_id|>{{ end }}{{ if .Prompt }}<|start_header_id|>user<|end_header_id|>

{{ .Prompt }}<|eot_id|>{{ end }}<|start_header_id|>assistant<|end_header_id|>

{{ .Response }}<|eot_id|>"""
SYSTEM """You are a helpful assistant. ä½ æ˜¯ä¸€ä¸ªä¹äºåŠ©äººçš„åŠ©æ‰‹ã€‚"""
PARAMETER temperature 0.2
PARAMETER num_keep 24
PARAMETER stop <|start_header_id|>
PARAMETER stop <|end_header_id|>
PARAMETER stop <|eot_id|>
```

- è¿è¡Œ

```bash
ollama create llama3-zh-inst -f Modelfile_llama3
ollama run llama3-zh-inst
```

# æŒ‡ä»¤å¾®è°ƒ

- æ¨¡å‹ä¸‹è½½ï¼š[llama-3-chinese-8b-instruct-v3](https://huggingface.co/hfl/llama-3-chinese-8b-instruct-v3/tree/main)
- æ•°æ®ï¼š[ruozhiba_gpt4](https://huggingface.co/datasets/hfl/ruozhiba_gpt4/tree/main)
- è®­ç»ƒå‚è€ƒï¼š[æŒ‡ä»¤ç²¾è°ƒè„šæœ¬](https://github.com/ymcui/Chinese-LLaMA-Alpaca-3/wiki/sft_scripts_zh)

è®­ç»ƒç¤ºæ„å›¾ï¼š

![Llama train](/img/ai/llama_train_inst.png)

æŠ¥é”™ï¼šæ˜¾å­˜ä¸è¶³ï¼ˆTODO: å¾…è§£å†³ï¼‰

- [CUDAæŠ¥é”™:Out of Memory](https://blog.csdn.net/Coldlebron/article/details/127575370)

# å‚è€ƒ

[^1]: ä¸å»ºè®®å•ç‹¬ä½¿ç”¨1.3Bæ¨¡å‹ï¼Œè€Œæ˜¯é€šè¿‡æŠ•æœºé‡‡æ ·æ­é…æ›´å¤§çš„æ¨¡å‹ï¼ˆ7Bã€13Bï¼‰ä½¿ç”¨ã€‚
[^2]: æœ¬é¡¹ç›®ä¸€ä»£æ¨¡å‹å’ŒäºŒä»£æ¨¡å‹çš„è¯è¡¨ä¸åŒï¼Œè¯·å‹¿æ··ç”¨ã€‚äºŒä»£LLaMAå’ŒAlpacaçš„è¯è¡¨ç›¸åŒã€‚
[^3]: æ‹¬å·å†…è¡¨ç¤ºåŸºäºNTKä¸Šä¸‹æ–‡æ‰©å±•æ”¯æŒçš„æœ€å¤§é•¿åº¦ã€‚
[^4]: Alpaca-2é‡‡ç”¨äº†Llama-2-chatç³»åˆ—æ¨¡æ¿ï¼ˆæ ¼å¼ç›¸åŒï¼Œæç¤ºè¯­ä¸åŒï¼‰ï¼Œè€Œä¸æ˜¯ä¸€ä»£Alpacaçš„æ¨¡æ¿ï¼Œè¯·å‹¿æ··ç”¨ã€‚
