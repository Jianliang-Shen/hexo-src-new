---
layout: post
title: "机密计算: 大模型安全解决方案"
index_img: /img/post_pics/cc/llm-sec-1.jpg
date: 2024-07-29 19:14:35
tags:
    - LLM
    - TEE
    - Confidential Compute
    - Security
categories: 
    - Security
---

随着大模型技术的高速发展，大模型在各个领域的应用日益广泛，从科研到商业，再到日常生活、办公等方方面面。

<!-- more -->

- [**百度：大模型安全解决方案**](https://anquan.baidu.com/product/llmsec)

## 大模型安全的重要性

首先，大模型在许多应用场景中处理大量敏感数据和个人信息，如用户的搜索记录、社交媒体互动和金融交易等。这使得数据泄露和隐私侵犯的风险不容忽视。一旦这些敏感信息遭受泄露，个人隐私权益可能会受到严重损害，甚至被用于恶意行为，如身份盗窃、诈骗和社会工程攻击。这不仅会对受害者造成经济损失，还可能导致社会的恐慌和不信任。

其次，大模型的强大能力也可能被用于进行各种形式的恶意攻击。模型的对抗性样本攻击，即针对模型的输入进行微小改动，从而欺骗模型产生错误预测，已成为一种常见的威胁。恶意使用者可以通过这种方式制造虚假信息，影响决策结果，如将误导性的信息传播到社交媒体平台，从而扰乱社会秩序。此外，大模型的生成能力也可能被用于生成虚假的内容，威胁到媒体的可信度和新闻的真实性。

另外，模型本身也可能成为攻击者的目标。**模型参数和权重的泄露可能导致知识产权的损失，甚至使恶意使用者能够复制或修改模型，进一步恶化风险。**对模型的针对性攻击，如投毒攻击，可能使模型的输出产生不良影响，从而影响到正常的业务运行。这些威胁可能在不经意间对企业和社会造成巨大的损失。此外，大模型的使用往往涉及到社会伦理和法律问题。例如，算法的歧视性问题，即模型在处理数据时产生的不公平或偏见，可能引发社会的不满和争议。

此外，大模型可能会被用于传播虚假信息、仇恨言论或不当内容，从而引发社会不安定和文化冲突。

最后，国家网信办联合国家发展改革委、教育部、科技部、工业和信息化部、公安部、广电总局公布《生成式人工智能服务管理暂行办法》，自2023年8月15日起施行，旨在促进生成式人工智能健康发展和规范应用，维护国家安全和社会公共利益，保护公民、法人和其他组织的合法权益。这既是促进生成式人工智能健康发展的重要要求，也是防范生成式人工智能服务风险的现实需要。

因此，确保大模型的安全性和可信度是一个紧迫的任务。需要综合运用技术手段、政策法规以及社会共识，建立起一套全面的大模型安全风险管理体系。通过逐一应对数据隐私保护、模型防御、内容合规、恶意行为检测等方面的挑战，我们能够更好地应对现实中的安全风险，保障个人权益和社会稳定。这也是本白皮书所要探讨的核心议题之一。

## 安全挑战与潜在威胁

- 数据安全与隐私问题
  - 传输截获风险
  - 运营方窥探风险
  - 模型记忆风险
- 模型流转/部署过程中的安全问题
  - 模型知识泄漏: 在将模型部署到生产环境中，模型的输出可能会暴露训练数据的一些信息。攻击者可以通过分析模型的输出，推断出训练数据的特征和分布，进而构建类似的数据集，甚至还原部分原始数据。
  - 模型逆向工程: 攻击者可能尝试通过逆向工程技术还原部署模型的架构、权重和训练数据。这可能导致知识产权盗窃、模型盗用和安全漏洞的暴露。逆向工程可能通过模型推理结果、输入输出分析以及梯度攻击等方式进行。
  - 输入数据的合法性和安全性：在模型部署阶段，恶意用户可能试图通过提供恶意输入来攻击系统。例如，输入中可能包含恶意代码、命令执行、注入语句或文件包含路径，从而导致安全漏洞。
  - 模型更新和演化：模型需要定期更新以保持性能和适应新的数据分布。然而，模型更新可能引入新的漏洞和问题。安全地更新模型需要考虑版本控制、验证新模型的安全性和稳定性，以及备份机制以防产生不良影响。
- AIGC 的内容合规问题
  - 个人隐私问题
    - Smart Compose 隐私问题
    - 语音助手隐私问题
    - 个性化内容生成隐私问题
  - 虚假信息和误导性内容
    - Deepfake 虚假视频
    - 虚假新闻和评论
    - 制造虚假证据
  - 民族仇恨言论和不当内容
  - 偏见和歧视问题
  - 淫秽色情内容
  - 政治/军事敏感内容
  - 恐怖/暴力内容
  - 版权和知识产权问题
  - 滥用和恶意使用
  - 责任和透明度
    - 责任归属
    - 透明度和解释性
- 大模型运营的业务安全问题
  - 前置业务环节
  - 大模型交互环节: 在大模型交互环节，本节将分别从用户的“提问行为“和”提问内容“两个维度展开”。首先是提问行为，在针对大模型发起提问时，黑产等不发分子围绕提问接口发起AIGC盗爬/垃圾提问/接口攻击/频控突破/资源侵占等攻击行为；针对大模型输出结果，黑灰产可以发起投毒反馈、恶意反馈等攻击行为。如下图所示，今年北京某公司起诉其多年的合作的伙伴某知名网校品牌，指其近期推出的数学大模型MathGPT和在某品牌学习机上线的AI助手，在未经其授权和许可情况下，爬取了海量数据，要求其公开道歉、删除数据资源，求偿1元，打响了AIGC盗爬的第一案。
  - 大模精调/推理环节

## 大模型安全解决方案

![解决方案](/img/post_pics/cc/llm-sec-2.png)

- 数据安全与隐私保护
  - 横向联邦大模型解决方案: 采用中心化的CS架构，中心节点为汇聚服务器，用于将不同参与方的结果数据进行汇聚，平衡各参与方的计算节奏，保持和管理最终的合并后的模型。每个参与方，采取弱侵入式的接入方式，部署参与方插件，用于和现有的算力平台进行结合，收集和管理本方的计算集群。
![联邦学习](/img/post_pics/cc/llm-sec-3.png)
  - 基于差分隐私的软件精调/推理方案: 差分隐私（differentialprivacy）是一个数据保护手段，通过使用随机噪声来确保请求信息的可见结果时，不会因为个体的变化而变化，实现仅分享可以描述数据库的一些统计特征、而不公开具体到个人的信息。这一特性可以被用来保护大模型在精调和推理时与云端服务端交互的用户数据隐私。
![差分隐私](/img/post_pics/cc/llm-sec-4.png)
  - 基于同态密码学的软件精调/推理方案: **同态密码学是一项联邦学习的关键技术，提供了在加密状态下对数据进行计算和处理的能力，从而保护数据的隐私和安全。对于大模型的数据保护思路，是通过同态密码学来实现大模型的计算逻辑，从而大模型可以接受密态化的数据输入，整体精调和推理过程完全是密态化的进行，最终的结果也是以密态的形式返回给客户端，**整个过程完全是密态化的，所以将此过程完全部署到在云上的服务端。而客户仅需要将本地的隐私数据密态化后上传给服务端，所有计算过程由云端外包完成，但是云端服务，不能获取到计算的内容。对于同态密码学方案，核心是如何通过同态密码学实现大模型的核心计算逻辑，其中主要包括，**Embedding，Transformer（Attention）和Header等大模型基础组件结构**。由于同态密码学计算复杂性和支持的计算有限，如何合理的利用同态密码学算法能达到可用性和精度的要求，实现精调和推理阶段隐私保护的方案。目前基于同态密码学方面的大模型研究，公开研究主要集中在推理阶段，也有少量的精调方面。根据所采用的同态密码学算法的实现不同，大致可以分成基于**全同态密码学FHE实现和基于MPC（SecureShare）**实现两大方向。
![同态密码](/img/post_pics/cc/llm-sec-5.png)
  - 可信执行环境解决方案: TEE能够作为云计算的信任根，保管根密钥，确保TEE外实体无法获取，还可以通过远程证明和负载度量值的结合，使公有云达到私有云的安全等级。对于私有化的场景，TEE可以充分发挥“飞地”的作用，将隐私敏感资产部署在其他实体。
    - 在如下大模型使用场景中保护敏感数据资产：
      - 在使用第三方大模型服务提供的精调和预测功能时，保护用户输入数据和精调产出模型的隐私
      - 在第三方部署大模型服务时，保护模型的隐私
      - 通过安全的设计与配置，可以运行复杂的分布式系统
      - 处于机密计算状态的处理器操作明文数据，不需要使用差分和同态等密码学算法，具备高性能处理海量数据的能力
      - 支持通用的 NLP 算法，模型和计算精度无损失
    - 解决方案:
      - TDX（TrustedDomianExtension）是英特尔新提出的能够部署硬件隔离的虚拟机（可信域，trusteddomain，TD）的技术框架
      - SEV（Secure Encrypted Virtualization）是 AMD 提出的机密虚拟机方案， 其推出时间较 TDX 早，因此软件生态较好，upstream linux kernel， openstack，kubevirt 和 libvirt 等虚拟化相关生态支持较好；
      - CSV（ChineseSecureVirtualization）是海光根据AMDSEV国产化的解决方案，使用国密算法，信任根全部国产化。
    - 百度提供的**可信执行环境解决方案（MesaTEE）**是基于硬件TEE的大模型机密计算方案，支持在Intel SGX，Intel TDX，AMD SEV-SNP和海光CSV等多种硬件TEE内进行大模型训练和推理。通过以PCIe穿透（passthrough）的方式访问**Nvidia H系列GPU和海光集成DCU**等具备机密计算能力的外部加速设备，MesaTEE能够获得与非机密计算相当的大模型计算性能，拥有良好的模型效率和用户体验。MesaTEE将传统虚拟机安全与TEE相结合，将可信启动过程记录到远程认证的度量值中，保证启动过程的安全，提高远程认证的真实性。机密虚拟机中运行的容器启动前，其数字签名会被校验，确保程序来源的合法性。隐私数据以透明加解密的方式落盘，保护数据隐私和安全的同时，提高应用的兼容性；非秘密的程序，通过建立哈希树（Hashtree）的方式，保证其完整性的同时，兼顾访问性能。机密虚拟机之间使用基于远程认证的透明加解密技术，确保通信过程中的数据隐私安全。MesaTEE深耕大模型使用场景，支持分布式训练、精调和推理，通过基于身份的访问控制，具备多租户数据及模型隔离管理和保护，多方数据训练和推理等数据融合功能。可信执行环境是云计算中不可或缺的一部分，它从硬件层面解决了软件根本的信任问题，是云计算的“根”。机密计算是大趋势，英特尔、AMD和英伟达等硬件提供商均提供了机密计算硬件解决方案。微软、亚马逊云、谷歌云和阿里云等均提供机密计算的设备和解决方案。百度、蚂蚁金服和字节跳动等均在使用机密计算为业务提供隐私及安全能力。
  - 基于安全沙箱的解决方案: 安全沙箱技术是一种通过构建隔离的可供调试、运行的安全环境，来分离模型、数据使用权和所有权的技术，同时提供模型精调计算所需的算力管理和通信等功能，保证模型拥有方的预训练模型在不出其定义的私有边界的前提下，数据拥有方可以完成模型精调任务。安全沙箱通过**界面隔离、环境隔离、网络隔离、执行隔离、数据隔离**五大隔离技术达到模型和数据的可用不可见。
- 模型保护方案
  - 语料数据管理：面对多渠道收集珍贵语料数据，如何实现高效的数据管理，防范模型原始语料数据泄漏，提高语料数据加工效率
  - 模型资产保护：大模型文件是企业核心数字资产，如何防范大模型文件在训练、推理、微调等环节的模型文件泄漏风险
  - 大模型语料数据安全管理与大模型资产全流程保护
